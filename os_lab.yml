## Run as
## TF_STATE=./tf_vmware/terraform.tfstate; ansible-playbook os_lab.yml --extra-vars "firstrun=true" 
## When not using a vault add: "--ask-vault-pass"


---

# - hosts: localhost
#   tasks:
#   - include_vars: .vault.yml

## Servers uitrollen
## Mag uit staan omdat we uitrollen met TF
#   roles:
#     - vmware-guest

# - hosts: localhost
#   tasks:
#   - debug: 'var=groups'



## install python 2
- hosts: all
  gather_facts: False

  tasks:
  - name: install python 2
    raw: |
      test -e /usr/bin/python || \
       (sudo apt -y update && sudo apt install -y python-minimal)
    when: firstrun is defined

#######################################################################
## common stuff
#######################################################################
- hosts: all
  gather_facts: True
  tasks:
  - name: "Build hosts file"
    lineinfile: 
      dest=/etc/hosts 
      regexp='.*{{ item }}$' 
      line="{{ hostvars[item].ansible_default_ipv4.address }} {{item}} {{ hostvars[item].ansible_hostname }}" 
      state=present
    with_items: 
      - "{{ groups['all'] }}"
    when: firstrun is defined

  - name: add-apt-repository
    shell: |
      add-apt-repository cloud-archive:rocky -y; apt-key adv \
       --keyserver keyserver.ubuntu.com --recv-keys 5EDB1B62EC4926EA
    when: firstrun is defined

#  - name: add-apt-repository rocky
#    apt_repository:
#      repo: cloud-archive:rocky

  - name: dist-upgrade
    apt:
      upgrade: dist
      update_cache: yes
      dpkg_options: 'force-confold,force-confdef'
    when: firstrun is defined
    ##retry so we can user forking
    register: apt_result
    retries: 5 
    until: apt_result is success

  - name: ensure common packages are installed
    apt:
      pkg:
        - chrony
        - software-properties-common
        - python-openstackclient 
      state: present
      update_cache: yes
    ##retry so we can use forking
    register: apt_result
    retries: 5 
    until: apt_result is success

  - name: configure chrony
    lineinfile:
      path=/etc/chrony/chrony.conf
      regexp='^allow'
      line='allow 10.0.0.0/24'
    notify: restart-chrony

  - name: template adminrc on all nodes (might come in handy)
    template:
      src=files/adminrc.j2
      dest={{item}}
      backup=yes
    with_items:
      - /root/.adminrc
      - /home/ubuntu/.adminrc
    tags: rc

  - name: add adminrc to bashrc on all nodes
    lineinfile:
      path={{item}}
      line='. ~/.adminrc'
    with_items:
      - /root/.bashrc
      - /home/ubuntu/.bashrc
    tags: rc


#######################################################################
## Control nodes
#######################################################################
- hosts: control
  tasks:
  - name: ensure certain packages are installed on control
    apt:
      pkg:
        - python-pymysql
        - python-memcache
        - memcached
        - etcd
        - apache2
        - libapache2-mod-wsgi
        - mariadb-server
        - rabbitmq-server
        - neutron-server
        - neutron-plugin-ml2
        - neutron-linuxbridge-agent
        - neutron-l3-agent
        - neutron-dhcp-agent
        - neutron-metadata-agent
      state: present
      update_cache: yes
    tags: pkg

## MySQL
  - name: template 99-openstack.cnf
    template:
      src=files/99-openstack.cnf.j2
      dest=/etc/mysql/mariadb.conf.d/99-openstack.cnf
      backup=yes
    notify: restart-mysql
    tags: database

  - name: create databases
    mysql_db:
      config_file=/etc/mysql/debian.cnf
      name={{ item }}
    with_items: "{{mysql_databases}}"
    tags: database

  - name: create users
    mysql_user:
      config_file=/etc/mysql/debian.cnf
      name={{item}}
      host='%'
      password="{{ DATABASE_PASS }}"
      priv='{{item}}.*:ALL'
    with_items: "{{mysql_databases}}"
    tags: database

## RabbitMQ
  - name: add openstack user to rabbitmq
    rabbitmq_user:
      user: openstack
      password: "{{RABBIT_PASS}}"
      vhost: /
      configure_priv: .*
      read_priv: .*
      write_priv: .*
      state: present

## Memcached
  - name: template memcached.conf
    template:
      src=files/memcached.conf.j2
      dest=/etc/memcached.conf
      backup=yes
    notify: restart-memcached

## ETCD
  - name: create etcd config folder
    file:
      path=/etc/etcd
      state=directory
      owner=etcd
      group=etcd

  - name: template etcd.conf.yml
    template:
      src=files/etcd.conf.yml.j2
      dest=/etc/etcd/etcd.conf.yml
      backup=yes
    notify: restart-etcd

## Keystone
  - name: install keystone
    apt:  pkg=keystone state=present update_cache=yes
    register: keystone
    tags: keystone

  - name: template keystone.conf.yml
    template:
      src=files/keystone.conf.j2
      dest=/etc/keystone/keystone.conf
      backup=yes
    notify: restart-keystone
    tags: keystone

  - name: chown /var/log/keystone directory
    file:
      path: /var/log/keystone
      state: directory
      owner: keystone
      group: syslog
      mode: 0775

  - name: retreive keystone table count
    shell: |
      mysql -e "SELECT COUNT(*) FROM information_schema.tables \
      WHERE table_schema = 'keystone';" -B  -N
    register: keystonetablecount
    tags: keystone

  - name: Populate the Identity service database
    shell: su -s /bin/sh -c "keystone-manage db_sync" keystone
    when: keystonetablecount.stdout|int < 10
    tags: keystone

  - name: Initialize Fernet key repositories
    shell: |
      keystone-manage fernet_setup --keystone-user keystone \
       --keystone-group keystone
      keystone-manage credential_setup --keystone-user keystone \
       --keystone-group keystone
    when: keystone.changed
    register: fernet
    tags: keystone

  - name: Bootstrap the Identity service
    shell: |
      keystone-manage bootstrap --bootstrap-password {{ ADMIN_PASS }} \
       --bootstrap-admin-url http://{{ hostvars[item].ansible_hostname }}:5000/v3/ \
       --bootstrap-internal-url http://{{ hostvars[item].ansible_hostname }}:5000/v3/ \
       --bootstrap-public-url http://{{ hostvars[item].ansible_hostname }}:5000/v3/ \
       --bootstrap-region-id RegionOne; exit 0
    become: yes
    become_user: root
    with_items: 
      - "{{ groups['control'] }}"
    when: fernet.changed
    tags: keystone

  - name: configure keystone domains, roles and users
    block:
      - name: add domains
        os_keystone_domain:
          cloud: "{{ooo}}"
          state: present
          name: "{{item.key}}"
          description: "{{item.value}}"
        with_dict: "{{keystone_domains}}"

      - name: add projects
        os_project:
          cloud: "{{ooo}}"
          name: "{{item.key}}"
          description: "{{item.value}}"
          domain_id: default
        with_dict: "{{keystone_projects}}"

      - name: add roles to keystone
        os_keystone_role: 
          cloud: "{{ooo}}"
          name: "{{item}}"
        with_items: "{{keystone_roles}}"

      - name: add users to keystone
        os_user: 
          cloud: "{{ooo}}"
          name: "{{item.key}}"
          password: "{{item.value.pass}}"
          update_password: on_create
          domain: default
        with_dict: "{{keystone_users}}"

      - name: assign roles to users in keystone
        os_user_role: 
          cloud: "{{ooo}}"
          user: "{{item.key}}"
          role: "{{item.value.role}}"
          project: "{{item.value.project}}"
        with_dict: "{{keystone_users}}"
    tags: 
    - keystone
    - keystone_users

  - name: prep services and endpoints
    block:
      - name: create services in keystone
        os_keystone_service:
          cloud: "{{ooo}}"
          name: "{{item.key}}"
          service_type: "{{item.value.type}}"
          description: "{{item.value.description}}"
        with_dict: "{{keystone_services}}"

      - name: create endpoints in keystone
        os_keystone_endpoint:
          cloud: "{{ooo}}"
          service: "{{item.service}}"
          endpoint_interface: "{{item.interface}}"
          url: "{{item.url}}"
          region: "{{item.region}}"
        with_items: "{{keystone_endpoints}}"
    tags: 
    - keystone
    - keystone_services


## Glance
  - name: install glance
    block:
      - apt:  pkg=glance state=present update_cache=yes
      - template:
          src=files/{{item}}.j2
          dest=/etc/glance/{{item}}
          backup=yes
        with_items:
          - glance-api.conf
          - glance-registry.conf
        notify: 
          - restart-glance-api
          - restart-glance-registry
      - shell: 
          mysql -e "SELECT COUNT(*) FROM information_schema.tables \
          WHERE table_schema = 'glance';" -B  -N
        register: glancetablecount
      - name: Populate database
        shell: su -s /bin/sh -c "glance-manage db_sync" glance
        when: glancetablecount.stdout|int < 10
    tags: glance

#######################################################################
## Nova controller
  - name: install nova
    block:
      - name: install nova packages
        apt:  pkg={{nova_packages}} state=present update_cache=yes

      - name: configure nova
        template:
          src=files/{{item}}.j2
          dest=/etc/{{item}}
          backup=yes
        with_items:
          - nova/nova.conf
        notify: 
          - restart-nova-api
          - restart-nova-conductor
          - restart-nova-scheduler
          - restart-nova-novncproxy

      - name: count nova tables
        shell: |
          mysql -e "SELECT COUNT(*) FROM information_schema.tables \
          WHERE table_schema = 'nova_api';" -B  -N
        register: novaapitablecount

      - name: Populate the Identity service database
        shell: su -s /bin/sh -c "nova-manage api_db sync" nova
        when: novaapitablecount.stdout|int < 10

      - name: count nova tables
        shell: |
          mysql -e "SELECT COUNT(*) FROM information_schema.tables \
          WHERE table_schema = 'nova';" -B  -N
        register: novatablecount

      - name: stop nova before populating database
        service:
          name: "{{item}}"
          state: stopped
        with_items:
          - nova-api
          - nova-conductor
          - nova-scheduler
          - nova-novncproxy
        when: novatablecount.stdout|int < 10

      - name: Populate databases
        shell: |
          su -s /bin/sh -c "nova-manage cell_v2 map_cell0" nova
          su -s /bin/sh -c "nova-manage cell_v2 create_cell \
           --name=cell1 \
           --verbose" nova 109e1d4b-536a-40d0-83c6-5f121b82b650
          su -s /bin/sh -c "nova-manage db sync" nova
        when: novatablecount.stdout|int < 10
        notify: 
          - restart-nova-api
          - restart-nova-conductor
          - restart-nova-scheduler
          - restart-nova-novncproxy
    tags: nova


#######################################################################
## Neutron controller
  - name: configure neutron controller
    block:
    - name: configure neutron
      template:
        src=files/{{item}}.j2
        dest=/etc/{{item}}
        backup=yes
      with_items:
        - neutron/neutron.conf
        - neutron/plugins/ml2/ml2_conf.ini
        - neutron/plugins/ml2/linuxbridge_agent.ini
        - neutron/l3_agent.ini
        - neutron/dhcp_agent.ini
        - neutron/metadata_agent.ini
      notify: 
        - restart-nova-api
        - restart-neutron-server
        - restart-neutron-linuxbridge-agent
        - restart-neutron-dhcp-agent
        - restart-neutron-metadata-agent
        - restart-neutron-l3-agent
    tags: neutron

  - name: retreive neutron table count
    shell: |
      mysql -e "SELECT COUNT(*) FROM information_schema.tables \
      WHERE table_schema = 'neutron';" -B  -N
    register: neutrontablecount
    tags: neutron

  - name: Populate the Identity service database
    shell: |
      su -s /bin/sh -c "neutron-db-manage \
      --config-file /etc/neutron/neutron.conf \
      --config-file /etc/neutron/plugins/ml2/ml2_conf.ini \
      upgrade head" neutron
    when: neutrontablecount.stdout|int < 10
    tags: neutron

  - name: configure sysctl
    sysctl:
      name: item.key
      value: item.value
    with_items:
      - net.bridge.bridge-nf-call-iptables: 1
      - net.bridge.bridge-nf-call-ip6tables: 1
    tags: neutron

  - name: ensure br_netfilter kernel module is available
    modprobe:
      name: br_netfilter
      state: present
    tags: neutron


  handlers:
  - name: restart-mysql
    service: name=mysql state=restarted
  - name: restart-memcached
    service: name=memcached state=restarted
  - name: restart-etcd
    service: name=etcd state=restarted
  - name: restart-chrony
    service: name=chrony state=restarted

  - name: restart-keystone
    service: name=keystone state=restarted

  - name: restart-glance-registry
    service: name=glance-registry state=restarted
  - name: restart-glance-api
    service: name=glance-api state=restarted

  - name: restart-nova-api
    service: name="nova-api" state=restarted
  - name: restart-nova-conductor
    service: name="nova-conductor" state=restarted
  - name: restart-nova-scheduler
    service: name="nova-scheduler" state=restarted
  - name: restart-nova-novncproxy
    service: name="nova-novncproxy" state=restarted

  - name: restart-neutron-server
    service: name="neutron-server" state=restarted
  - name: restart-neutron-linuxbridge-agent
    service: name="neutron-linuxbridge-agent" state=restarted
  - name: restart-neutron-dhcp-agent
    service: name="neutron-dhcp-agent" state=restarted
  - name: restart-neutron-metadata-agent
    service: name="neutron-metadata-agent" state=restarted
  - name: restart-neutron-l3-agent
    service: name="neutron-l3-agent" state=restarted



#######################################################################
## Compute nodes
#######################################################################

- hosts: compute
  tasks:
## pakages
  - name: install nova packages
    apt:  pkg={{packages}} state=present update_cache=yes
    tags: compute

## Configure nova & neutron
  - name: configure nova & neutron
    template:
      src=files/{{item}}.j2
      dest=/etc/{{item}}
      backup=yes
    with_items:
      - nova/nova.conf
      - nova/nova-compute.conf
      - neutron/neutron.conf
      - neutron/plugins/ml2/linuxbridge_agent.ini
    notify: 
      - restart-nova-compute
      - restart-neutron-linuxbridge-agent
    tags: compute

  - name: configure sysctl
    sysctl:
      name: item.key
      value: item.value
    with_items:
      - net.bridge.bridge-nf-call-iptables: 1
      - net.bridge.bridge-nf-call-ip6tables: 1
    tags: compute

  - name: ensure br_netfilter kernel module is available
    modprobe:
      name: br_netfilter
      state: present
    tags: compute

  handlers:
  - name: restart-nova-compute
    service: name=nova-compute state=restarted
  - name: restart-neutron-linuxbridge-agent
    service: name=neutron-linuxbridge-agent state=restarted


#######################################################################
## Finish up control nodes
#######################################################################

- hosts: control
  tasks:
  - name: add compute nodes to cell database
    shell: |
      . ~/.adminrc && su -s /bin/sh -c "nova-manage cell_v2 \
      discover_hosts --verbose" nova; exit 0
    when: firstrun is defined
    tags: compute



