## Run as
## TF_STATE=./tf_openstack/terraform.tfstate ansible-playbook os_lab.yml  --extra-vars "firstrun=true" --start-at="retreive keystone table count"
## When using a vault add: "--ask-vault-pass"


---

## install python via raw module
- hosts: all
  gather_facts: False

  tasks:
  - name: install python 2
    raw: |
      test -e /usr/bin/python || \
       (sudo apt -y update && sudo apt install -y python-minimal)
    when: firstrun is defined

#######################################################################
## common stuff
#######################################################################
- hosts: all
  gather_facts: True
  tasks:
  - debug: var=control_node_name
    tags: debug

  # - debug: var=control_node_ip_remote
  #   tags: debug

  - name: "Build hosts file"
    lineinfile: 
      dest=/etc/hosts 
      regexp='{{ hostvars[item].ansible_default_ipv4.address }}.*' 
      line="{{ hostvars[item].ansible_default_ipv4.address }} {{ hostvars[item].ansible_hostname }}" 
      state=present
    with_items: 
      - "{{ groups['all'] }}"
    when: firstrun is defined

  - name: add-apt-repository
    shell: |
      add-apt-repository cloud-archive:rocky -y; apt-key adv \
       --keyserver keyserver.ubuntu.com --recv-keys 5EDB1B62EC4926EA
    when: firstrun is defined

#  - name: add-apt-repository rocky
#    apt_repository:
#      repo: cloud-archive:rocky

  - name: dist-upgrade
    apt:
      upgrade: dist
      update_cache: yes
      dpkg_options: 'force-confold,force-confdef'
    when: firstrun is defined
    ##retry so we can use forking
    register: apt_result
    retries: 10
    until: apt_result is success

  - name: ensure common packages are installed
    apt:
      pkg:
        - chrony
        - software-properties-common
        - python-openstackclient 
      state: present
      update_cache: yes
    ##retry so we can use forking
    register: apt_result
    retries: 10
    until: apt_result is success

  - name: configure chrony
    lineinfile:
      path=/etc/chrony/chrony.conf
      regexp='^allow'
      line='allow 10.0.0.0/24'
    notify: restart-chrony

  - name: set timezone
    timezone:
      name: Europe/Bratislava

  - name: template adminrc on all nodes (might come in handy)
    template:
      src=files/adminrc.j2
      dest={{item}}
      backup=yes
    with_items:
      - /root/.adminrc
      - /home/ubuntu/.adminrc
    tags: rc

  - name: add adminrc to bashrc on all nodes
    lineinfile:
      path={{item}}
      line='. ~/.adminrc'
    with_items:
      - /root/.bashrc
      - /home/ubuntu/.bashrc
    tags: rc

  handlers:
  - name: restart-chrony
    service: name=chrony state=restarted

#######################################################################
## Control nodes
#######################################################################
- hosts: control
  tasks:
## pakages
  - name: ensure certain packages are installed on control
    apt:  pkg={{packages}} state=present update_cache=yes
    tags: pkg

## MySQL
  - name: template 99-openstack.cnf
    template:
      src=files/99-openstack.cnf.j2
      dest=/etc/mysql/mariadb.conf.d/99-openstack.cnf
      backup=yes
    tags: database
    register: mysqlconfig

  - name: reload mysql before next steps
    service: 
      name=mysql 
      state=restarted
    when: mysqlconfig.changed

  - name: create databases
    mysql_db:
      config_file=/etc/mysql/debian.cnf
      name={{ item }}
      encoding=utf8
      collation=utf8_general_ci
    with_items: "{{mysql_databases}}"
    tags: database

# grant every user all privileges since ansible cant provide multiple grants thats needed for nova_cell0 etc.
  - name: create users
    mysql_user:
      config_file=/etc/mysql/debian.cnf
      name={{item}}
      host='%'
      password="{{ DATABASE_PASS }}"
      priv='*.*:ALL'
      # priv='{{item}}.*:ALL'
    with_items: "{{mysql_databases}}"
    tags: database

## RabbitMQ
  - name: add openstack user to rabbitmq
    rabbitmq_user:
      user: openstack
      password: "{{RABBIT_PASS}}"
      vhost: /
      configure_priv: .*
      read_priv: .*
      write_priv: .*
      state: present

## Memcached
  - name: template memcached.conf
    template:
      src=files/memcached.conf.j2
      dest=/etc/memcached.conf
      backup=yes
    notify: restart-memcached

## ETCD
  - name: create etcd config folder
    file:
      path=/etc/etcd
      state=directory
      owner=etcd
      group=etcd

  - name: template etcd.conf.yml
    template:
      src=files/etcd.conf.yml.j2
      dest=/etc/etcd/etcd.conf.yml
      backup=yes
    notify: restart-etcd

#######################################################################
## Keystone
  - name: install keystone
    apt:  pkg=keystone state=present update_cache=yes
    register: keystone
    tags: keystone

  - name: template keystone.conf.yml
    template:
      src=files/keystone.conf.j2
      dest=/etc/keystone/keystone.conf
      backup=yes
    notify: restart-keystone
    tags: keystone

  - name: chown /var/log/keystone directory
    file:
      path: /var/log/keystone
      state: directory
      owner: keystone
      group: syslog
      mode: 0775

  - name: retreive keystone table count
    shell: |
      mysql -e "SELECT COUNT(*) FROM information_schema.tables \
      WHERE table_schema = 'keystone';" -B  -N
    register: keystonetablecount
    tags: keystone

  - name: Populate the Identity service database
    shell:  su -s /bin/sh -c "keystone-manage db_sync" keystone
    when: keystonetablecount.stdout|int < 10
    tags: keystone

  - name: Initialize Fernet key repositories
    shell: |
      keystone-manage fernet_setup --keystone-user keystone \
       --keystone-group keystone
      keystone-manage credential_setup --keystone-user keystone \
       --keystone-group keystone
    when: firstrun is defined
    register: fernet
    tags: keystone

  - name: Bootstrap the Identity service
    shell: |
      keystone-manage bootstrap --bootstrap-password {{ ADMIN_PASS }} \
       --bootstrap-admin-url http://{{ control_node_ip }}:5000/v3/ \
       --bootstrap-internal-url http://{{ control_node_ip }}:5000/v3/ \
       --bootstrap-public-url http://{{ control_node_ip_remote }}:5000/v3/ \
       --bootstrap-region-id RegionOne
    become: yes
    become_user: root
    with_items: 
      - "{{ groups['control'] }}"
    when: firstrun is defined
    tags: keystone

  - name: configure keystone domains, roles and users
    block:
      - name: add domains
        os_keystone_domain:
          cloud: "{{ooo}}"
          state: present
          name: "{{item.key}}"
          description: "{{item.value}}"
        with_dict: "{{keystone_domains}}"

      - name: add projects
        os_project:
          cloud: "{{ooo}}"
          name: "{{item.key}}"
          description: "{{item.value}}"
          domain_id: default
        with_dict: "{{keystone_projects}}"

      - name: add roles to keystone
        os_keystone_role: 
          cloud: "{{ooo}}"
          name: "{{item}}"
        with_items: "{{keystone_roles}}"

      - name: add users to keystone
        os_user: 
          cloud: "{{ooo}}"
          name: "{{item.key}}"
          password: "{{item.value.pass}}"
          update_password: on_create
          domain: default
        with_dict: "{{keystone_users}}"

      - name: assign roles to users in keystone
        os_user_role: 
          cloud: "{{ooo}}"
          user: "{{item.key}}"
          role: "{{item.value.role}}"
          project: "{{item.value.project}}"
        with_dict: "{{keystone_users}}"
    tags: 
    - keystone
    - keystone_users

  - name: prep services and endpoints
    block:
      - name: create services in keystone
        os_keystone_service:
          cloud: "{{ooo}}"
          name: "{{item.key}}"
          service_type: "{{item.value.type}}"
          description: "{{item.value.description}}"
        with_dict: "{{keystone_services}}"

      - name: create endpoints in keystone
        os_keystone_endpoint:
          cloud: "{{ooo}}"
          service: "{{item.service}}"
          endpoint_interface: "{{item.interface}}"
          url: "{{item.url}}"
          region: "{{item.region}}"
        with_items: "{{keystone_endpoints}}"
    tags: 
    - keystone
    - keystone_services


#######################################################################
## Glance
  - name: install glance
    block:
      - name: configure glance
        template:
          src=files/{{item}}.j2
          dest=/etc/glance/{{item}}
          backup=yes
        with_items:
          - glance-api.conf
          - glance-registry.conf
        notify: 
          - restart-glance-api
          - restart-glance-registry

      - name: count glance tables
        shell: |
          mysql -e "SELECT COUNT(*) FROM information_schema.tables \
          WHERE table_schema = 'glance';" -B  -N
        register: glancetablecount

      - name: Populate glance database
        shell: su -s /bin/sh -c "glance-manage db_sync" glance
        when: glancetablecount.stdout|int < 10
    tags: glance


#######################################################################
## Nova controller
  - name: configure nova
    block:
      - name: configure nova
        template:
          src=files/{{item}}.j2
          dest=/etc/{{item}}
          backup=yes
        with_items:
          - nova/nova.conf
        notify: 
          - restart-nova-api
          - restart-nova-conductor
          - restart-nova-scheduler
          - restart-nova-novncproxy

      - name: count nova api tables
        shell: |
          mysql -e "SELECT COUNT(*) FROM information_schema.tables \
          WHERE table_schema = 'nova_api';" -B  -N
        register: novaapitablecount

      - name: Populate the Nova API database
        shell: su -s /bin/sh -c "nova-manage api_db sync" nova
        when: novaapitablecount.stdout|int < 10

      - name: count nova tables
        shell: |
          mysql -e "SELECT COUNT(*) FROM information_schema.tables \
          WHERE table_schema = 'nova';" -B  -N
        register: novatablecount

      - name: stop nova before populating database
        service:
          name: "{{item}}"
          state: stopped
        with_items:
          - nova-api
          - nova-conductor
          - nova-scheduler
          - nova-novncproxy
        when: novatablecount.stdout|int < 10

      - name: Populate nova databases
        shell: |
          su -s /bin/sh -c "nova-manage cell_v2 map_cell0" nova
          su -s /bin/sh -c "nova-manage cell_v2 create_cell \
           --name=cell1 \
           --verbose" nova 109e1d4b-536a-40d0-83c6-5f121b82b650
          su -s /bin/sh -c "nova-manage db sync" nova
        when: novatablecount.stdout|int < 10
        notify: 
          - restart-nova-api
          - restart-nova-conductor
          - restart-nova-scheduler
          - restart-nova-novncproxy
    tags: nova


#######################################################################
## Neutron controller
  - name: configure neutron controller
    block:
    - name: configure neutron
      template:
        src=files/{{item}}.j2
        dest=/etc/{{item}}
        backup=yes
      with_items:
        - neutron/neutron.conf
        - neutron/plugins/ml2/ml2_conf.ini
        - neutron/plugins/ml2/linuxbridge_agent.ini
        - neutron/l3_agent.ini
        - neutron/dhcp_agent.ini
        - neutron/metadata_agent.ini
      notify: 
        - restart-nova-api
        - restart-neutron-server
        - restart-neutron-linuxbridge-agent
        - restart-neutron-dhcp-agent
        - restart-neutron-metadata-agent
        - restart-neutron-l3-agent
    tags: neutron

  - name: retreive neutron table count
    shell: |
      mysql -e "SELECT COUNT(*) FROM information_schema.tables \
      WHERE table_schema = 'neutron';" -B  -N
    register: neutrontablecount
    tags: neutron

  - name: Populate the Identity service database
    shell: |
      su -s /bin/sh -c "neutron-db-manage \
      --config-file /etc/neutron/neutron.conf \
      --config-file /etc/neutron/plugins/ml2/ml2_conf.ini \
      upgrade head" neutron
    when: neutrontablecount.stdout|int < 10
    tags: neutron

  - name: configure sysctl
    sysctl:
      name: item.key
      value: item.value
    with_dict:
      - net.bridge.bridge-nf-call-iptables: 1
      - net.bridge.bridge-nf-call-ip6tables: 1
    tags: neutron
    ##retry doesnt work, so ignore errors
    ignore_errors: yes

    ##and try again the ugly way
  - name: configure sysctl
    sysctl:
      name: item.key
      value: item.value
    with_dict:
      - net.bridge.bridge-nf-call-iptables: 1
      - net.bridge.bridge-nf-call-ip6tables: 1
    tags: neutron
    ignore_errors: yes

  - name: ensure br_netfilter kernel module is available
    modprobe:
      name: br_netfilter
      state: present
    tags: neutron


#######################################################################
## Openstack-dashboard
  - name: configure Openstack-dashboard
    template:
      src=files/openstack-dashboard/local_settings.py.j2
      dest=/etc/openstack-dashboard/local_settings.py
      backup=yes
    notify: 
      - restart-apache2


  handlers:
  - name: restart-mysql
    service: name=mysql state=restarted
  - name: restart-memcached
    service: name=memcached state=restarted
  - name: restart-etcd
    service: name=etcd state=restarted
  - name: restart-apache2
    service: name=apache2 state=restarted

  - name: restart-keystone
    service: name=keystone state=restarted

  - name: restart-glance-registry
    service: name=glance-registry state=restarted
  - name: restart-glance-api
    service: name=glance-api state=restarted

  - name: restart-nova-api
    service: name="nova-api" state=restarted
  - name: restart-nova-conductor
    service: name="nova-conductor" state=restarted
  - name: restart-nova-scheduler
    service: name="nova-scheduler" state=restarted
  - name: restart-nova-novncproxy
    service: name="nova-novncproxy" state=restarted

  - name: restart-neutron-server
    service: name="neutron-server" state=restarted
  - name: restart-neutron-linuxbridge-agent
    service: name="neutron-linuxbridge-agent" state=restarted
  - name: restart-neutron-dhcp-agent
    service: name="neutron-dhcp-agent" state=restarted
  - name: restart-neutron-metadata-agent
    service: name="neutron-metadata-agent" state=restarted
  - name: restart-neutron-l3-agent
    service: name="neutron-l3-agent" state=restarted



#######################################################################
## Compute nodes
#######################################################################

- hosts: compute
  tasks:
## pakages
  - name: install nova packages
    apt:  pkg={{packages}} state=present update_cache=yes
    tags: compute

## Configure nova & neutron
  - name: configure nova & neutron
    template:
      src=files/{{item}}.j2
      dest=/etc/{{item}}
      backup=yes
    with_items:
      - nova/nova.conf
      - nova/nova-compute.conf
      - neutron/neutron.conf
      - neutron/plugins/ml2/linuxbridge_agent.ini
    notify: 
      - restart-nova-compute
      - restart-neutron-linuxbridge-agent
    tags: compute

  - name: configure sysctl
    sysctl:
      name: item.key
      value: item.value
    with_items:
      - net.bridge.bridge-nf-call-iptables: 1
      - net.bridge.bridge-nf-call-ip6tables: 1
    tags: compute

  - name: ensure br_netfilter kernel module is available
    modprobe:
      name: br_netfilter
      state: present
    tags: compute

  handlers:
  - name: restart-nova-compute
    service: name=nova-compute state=restarted
  - name: restart-neutron-linuxbridge-agent
    service: name=neutron-linuxbridge-agent state=restarted


#######################################################################
## Finish up control nodes
#######################################################################

- hosts: control
  tasks:
  - name: add compute nodes to cell database
    shell: |
      . ~/.adminrc && su -s /bin/sh -c "nova-manage cell_v2 \
      discover_hosts --verbose" nova
    when: firstrun is defined
    tags: compute

  # - name: Create tiny flavor
  #   os_nova_flavor:
  #     cloud: "{{ooo}}"
  #     state: present
  #     name: tiny3
  #     ram: 512
  #     vcpus: 1
  #     disk: 10
  #     ephemeral: 10
  #   tags: finalize

  - name: download cirros image
    get_url:
      url: http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img
      dest: ~/cirros-0.4.0-x86_64-disk.img
    when: firstrun is defined
    tags: finalize

  - name: upload cirros image
    shell: |
      . ~/.adminrc && openstack image create "cirros" \
        --file ~/cirros-0.4.0-x86_64-disk.img --disk-format qcow2 \
        --container-format bare --public
    when: firstrun is defined
    tags: finalize

  - name: get openstack services
    shell: |
      . ~/.adminrc 
      openstack image list
      openstack domain list
      openstack project list
      openstack user list
      openstack compute service list
      openstack image list
    register: show_result
    tags: 
      - show_result
      - finalize

  - debug: var=show_result.stdout_lines
    tags: 
      - show_result
      - finalize

  # - debug: "demo" user pass= "{{DEMO_PASS}}"
  #   tags: 
  #     - show_result
  #     - finalize

  # - debug: "myuser" user pass= "{{my_openstack_pass}}"
  #   tags: 
  #     - show_result
  #     - finalize

  - debug: |
      "admin" user pass= "{{ ADMIN_PASS }}"
      "myuser" user pass= "{{my_openstack_pass}}"
      "demo" user pass= "{{DEMO_PASS}}"
    tags: 
      - show_result
      - finalize
